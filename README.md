# BCSS Breast Cancer Semantic Segmentation

é†«å­¸å½±åƒèªç¾©åˆ†å‰²å°ˆæ¡ˆ - é‡å°ä¹³è…ºç™Œçµ„ç¹”åˆ‡ç‰‡é€²è¡Œå¤šé¡åˆ¥åˆ†å‰²

## ğŸ“Š å°ˆæ¡ˆæ¦‚è¿°

- **ä»»å‹™**: 3 é¡èªç¾©åˆ†å‰² (èƒŒæ™¯, é¡åˆ¥1, é¡åˆ¥2)
- **åœ–åƒå¤§å°**: 224Ã—224
- **æ¨¡å‹**: U-Net with Attention
- **è³‡æ–™å¢å¼·**: 2.5x å¼·åº¦
- **å¾Œè™•ç†**: å½¢æ…‹å­¸æ¸…ç† + TTA

## ğŸ¯ æ€§èƒ½

| æŒ‡æ¨™ | æ•¸å€¼ |
|------|------|
| **Val mIoU** | 51.2% |
| **Train mIoU** | 48.7% |
| **Val Accuracy** | 74.1% |
| **è¨“ç·´æ™‚é–“** | ~4 å°æ™‚ (50 epochs) |

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒè¨­ç½®

```bash
# å‰µå»º conda ç’°å¢ƒ
conda create -f lab4.yml
conda activate bcss

```

### 2. è¨“ç·´æ¨¡å‹

```bash
python train_main.py
```

### 3. åƒ…é æ¸¬ (ä½¿ç”¨å·²è¨“ç·´æ¨¡å‹)

```bash
python predict_only.py --model ckpt/20251019_173024/best_model_loss-0.2106_mIoU-0.512.pt
```

## ğŸ“ å°ˆæ¡ˆçµæ§‹

```
bcss_segmentation/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py              # æ‰€æœ‰é…ç½®åƒæ•¸
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ augmentation.py        # æ•¸æ“šå¢å¼· (2.5x)
â”‚   â”œâ”€â”€ dataset.py             # æ•¸æ“šè¼‰å…¥
â”‚   â”œâ”€â”€ losses.py              # æå¤±å‡½æ•¸ (å«åŠ æ¬ŠCE)
â”‚   â”œâ”€â”€ model.py               # U-Net æ¨¡å‹
â”‚   â”œâ”€â”€ postprocess.py         # å¾Œè™•ç†å‡½æ•¸
â”‚   â””â”€â”€ utils.py               # å·¥å…·å‡½æ•¸
â”œâ”€â”€ train_main.py              # ä¸»è¨“ç·´è…³æœ¬
â”œâ”€â”€ predict_only.py            # åƒ…é æ¸¬è…³æœ¬
â”œâ”€â”€ analyze_object_sizes.py    # ç‰©é«”å¤§å°åˆ†æ
â””â”€â”€ BCSS/                      # æ•¸æ“šé›†ç›®éŒ„
    â”œâ”€â”€ train/
    â”œâ”€â”€ train_mask/
    â”œâ”€â”€ val/
    â”œâ”€â”€ val_mask/
    â””â”€â”€ test/
```

## ğŸ”§ é—œéµæ”¹é€²

### 1. é¡åˆ¥æ¬Šé‡ (èƒŒæ™¯ 0.2)
```python
CLASS_WEIGHTS = [0.2, 1.0, 1.0]  # æ¸›å°‘èƒŒæ™¯éåº¦é æ¸¬
```

### 2. è¨“ç·´åƒæ•¸å„ªåŒ–
```python
MAX_LR = 3e-4        # é™ä½å­¸ç¿’ç‡
MAX_EPOCHS = 40      # æ¸›å°‘ epochs
```

### 3. å¾Œè™•ç†
- å½¢æ…‹å­¸æ¸…ç† (é–‹/é–‰é‹ç®—)
- ç§»é™¤å°ç‰©é«” (< 30 åƒç´ )
- å¡«å……ç©ºæ´
- æ¸¬è©¦æ™‚å¢å¼· (TTA 4x)

### 4. æ•¸æ“šå¢å¼· 2.5x
- æ›´å¼·çš„å¹¾ä½•è®Šæ›
- æ›´å¤šé¡è‰²å¢å¼·
- å½ˆæ€§è®Šå½¢
- CLAHE å°æ¯”åº¦å¢å¼·

## ğŸ“ é…ç½®èªªæ˜

ç·¨è¼¯ `config/config.py` èª¿æ•´åƒæ•¸:

```python
# è¨“ç·´åƒæ•¸
BATCH_SIZE = 48
MAX_LR = 3e-4
MAX_EPOCHS = 40

# é¡åˆ¥æ¬Šé‡
CLASS_WEIGHTS = [0.2, 1.0, 1.0]

# å¾Œè™•ç†
POST_PROCESS_MIN_SIZE = 30        # èª¿æ•´ä»¥æ”¹è®Šæ¸…ç†å¼·åº¦
POST_PROCESS_KERNEL_SIZE = 3      # å½¢æ…‹å­¸ kernel
USE_TTA = True                    # æ¸¬è©¦æ™‚å¢å¼·
```

## ğŸ“ˆ ç›£æ§è¨“ç·´

```bash
# ä½¿ç”¨ TensorBoard
tensorboard --logdir logs --port 6006
```

## ğŸ” åˆ†æå·¥å…·

### åˆ†æç‰©é«”å¤§å°åˆ†å¸ƒ
```bash
python analyze_object_sizes.py ./BCSS/train_mask/
```

è¼¸å‡º:
- ç‰©é«”å¤§å°çµ±è¨ˆ
- åˆ†ä½ˆåœ–
- å»ºè­°çš„ `min_size` åƒæ•¸

## ğŸ“š æ–‡æª”

- `IMPROVEMENTS.md` - è©³ç´°æ”¹é€²èªªæ˜
- `PERFORMANCE_TARGET.md` - æ€§èƒ½ç›®æ¨™èˆ‡åˆ†æ
- `POSTPROCESS_TUNING.md` - å¾Œè™•ç†åƒæ•¸èª¿å„ªæŒ‡å—

## ğŸ› å¸¸è¦‹å•é¡Œ

### Q: è¨˜æ†¶é«”ä¸è¶³ï¼Ÿ
```python
# é™ä½ batch size
BATCH_SIZE = 32  # æˆ– 24, 16
```

### Q: è¨“ç·´å¤ªæ…¢ï¼Ÿ
```python
# é—œé–‰ TTA (é æ¸¬éšæ®µ)
USE_TTA = False
```

### Q: éæ“¬åˆï¼Ÿ
```python
# å¢åŠ æ•¸æ“šå¢å¼·
# ç·¨è¼¯ src/augmentation.py æé«˜å„é … p å€¼
```

## ğŸ“Š è¼¸å‡º

è¨“ç·´å®Œæˆå¾Œæœƒç”Ÿæˆ:
- `ckpt/<timestamp>/best_model_*.pt` - æœ€ä½³æ¨¡å‹
- `logs/training_history.png` - è¨“ç·´æ›²ç·š
- `output/output.csv` - é æ¸¬çµæœ

## ğŸ™ è‡´è¬

åŸºæ–¼ U-Net æ¶æ§‹ï¼Œæ•´åˆå¤šç¨®æœ€ä½³å¯¦è¸

## ğŸ“„ æˆæ¬Š

è«‹éµå®ˆæ•¸æ“šé›†çš„ä½¿ç”¨æ¢æ¬¾
